# rnn-sac (WIP)
Evaluating the Soft-Actor Critic using an RNN policy on meta-world environments.


TODO: Write summary on the goal of the experiment, lack of base implementation of RNN SAC in popular frameworks like SB3

TODO: Write down th experiment results of the different methods 

## TODO:
- Reference usage of the SpinningUp original implementation
- Evaluate on gridworld, which requires a discrete policy
- Introduce Garage experiments
- Refactor experiments due to path change


**References**
- [Hindsight Experience Replay](https://arxiv.org/abs/1707.01495)
- [RL2: Fast Reinforcement Learning via Slow Reinforcement Learning](https://arxiv.org/abs/1611.02779)
- [Memory-based control with recurrent neural networks](https://arxiv.org/abs/1512.04455)
- [Revisiting Fundamentals of Experience Replay](https://arxiv.org/abs/2007.06700)
- [Learning to Reinforcement Learn](https://arxiv.org/abs/1611.05763)
- [Soft Actor-Critic Algorithms and Applications](https://arxiv.org/abs/1812.05905)
- [Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning](https://arxiv.org/abs/1910.10897)